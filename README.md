# Ego4D Dataset: Episodic memory task with NLQ and Synthetic Query Generation with LLM

Egocentric vision provides a unique perspective on human activities by capturing visual information from the user's point of view and modeling interactions with objects, environments and people. 
This project addresses the Natural Language Queries (NLQ) benchmark from the Ego4D dataset, which aims to identify the temporal segment in a video corresponding to a natural language query. 
Building on prior works, we replicate baseline models (VSLBase and VSLNet) with various combinations of textual and pre-extracted visual features. 
Additionally, we propose an extension based on automatically generating synthetic queries with Large Language Models (LLMs), aiming to expand the training set and improve model generalization.

Project report can be downloaded "project_report.pdf"
